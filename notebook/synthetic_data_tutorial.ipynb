{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poeem Tutorial\n",
    "\n",
    "In this notebook, we will demonstrate how to use *poeem* to jointly learn embedding index together with retrieval model. In addition to learning how to use *poeem*, you will also learn\n",
    "\n",
    "- Write a simple embedding retrieval model\n",
    "- Nearest neighbor search with brute force\n",
    "- Approximate nearest neighbor (ANN) search with Faiss - a Facebook open source library for ANN search with separately already learned embeddings\n",
    "- Approximate nearest neighbor (ANN) search with *Poeem* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import poeem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, *poeem* only supports Tensorflow 1.15, other tensorflow versions have not been tested. Users may need to make minor changes accordingly to let it run on other versions of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.__version__[:4] == '1.15'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "release gpu source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy data\n",
    "\n",
    "To demonstrate how *poeem* works, here we synthesizes a toy data for a quick tutorial. More real-world and larger data set tutorial is given [here]() \n",
    "\n",
    "In this toy data, the query and item are both represented as numerical ID numbers, which is simply also the row indices to their embedding matrices. Specifically, \n",
    "\n",
    "- a query is an integer number ranging from 0 to *vocab_size* (10,000 in this tutorial)\n",
    "- a item is an integer number ranging from 0 to *vocab_size* (10,000 in this tutorial)\n",
    "- a query ending with last two digits as *xy*, will retrieve items ending with last 4 digits as *abcd* where any two of them equal to x and y, e.g., a=x, b=y, or c=x, b=y and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000000  # number of training examples\n",
    "VOCAB_SIZE = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the data\n",
    "query = np.random.randint(0, high=VOCAB_SIZE, size=N)\n",
    "item = np.random.randint(0, high=VOCAB_SIZE, size=N)\n",
    "\n",
    "d, c, b, a = item % 10, (item // 10) % 10, (item // 100) % 10, (item // 1000) % 10\n",
    "\n",
    "def get_xy(a, axis):\n",
    "    idx = np.random.rand(*a.shape).argsort(axis=axis)\n",
    "    shuffled = np.take_along_axis(a,idx,axis=axis)\n",
    "    return shuffled[:, 0], shuffled[:, 1]\n",
    "\n",
    "x, y = get_xy(np.stack([a, b, c, d], axis=1), 1)\n",
    "query = (query // 100) * 100 + x * 10 + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the synthetic data to make sure the pattern is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9991, 2451, 6431, 7001, 6125, 5145, 2212, 4948,  135, 4029]),\n",
       " array([1392, 9195, 2391, 3100, 2535, 1945, 2122, 5842, 6435, 2219])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[query[:10], item[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)\n",
    "np.save('./data/query.npy', query)\n",
    "np.save('./data/item.npy', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training section, we will write a very simple embedding retrieval model for demonstration. Please be advised that this embedding model is solely for tutorial but not immediately applicable to real-world industrial systems yet where more practical techniques are necessary.\n",
    "\n",
    "First let's define some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCH = 3\n",
    "EMB_DIM = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, let's leverage the Tensorflow Estimator API with custom model_fn where we can define the model by ourselves and reuse the other convenient utilities to train the model.\n",
    "\n",
    "The queries and items are represented as separate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    query_column = tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='query',\n",
    "            vocabulary_list=range(VOCAB_SIZE),\n",
    "            dtype=tf.int32),\n",
    "        dimension=EMB_DIM)\n",
    "    item_column = tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='item',\n",
    "            vocabulary_list=range(VOCAB_SIZE),\n",
    "            dtype=tf.int32),\n",
    "        dimension=EMB_DIM)\n",
    "    \n",
    "    query_emb = tf.feature_column.input_layer(features, [query_column])\n",
    "    item_emb = tf.feature_column.input_layer(features, [item_column])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, predictions={'query': query_emb, 'item': item_emb})\n",
    "\n",
    "    def cosine(a, b):\n",
    "        a = tf.nn.l2_normalize(a, axis=1)\n",
    "        b = tf.nn.l2_normalize(b, axis=1)\n",
    "        return tf.matmul(a, b, transpose_b=True)\n",
    "\n",
    "    scores = cosine(query_emb, item_emb)\n",
    "\n",
    "    batch_size = tf.shape(query_emb)[0]\n",
    "    loss = tf.reduce_sum(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=tf.eye(batch_size),\n",
    "            logits=scores * 30))  # 1/30 is softmax temperature. Not carefully tune.\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(LEARNING_RATE)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, train_op=train_op, predictions={'query': query_emb, 'item': item_emb})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, let's define an input function that feeds data into the *model_fn* defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({'query': query.astype(np.int32), 'item': item.astype(np.int32)})\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).repeat(EPOCH)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to train the model with the above defined *model_fn* and *input_fn* by simply two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './retrieve_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2ef54b4350>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_22867/3130990966.py:15: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/embedding_ops.py:802: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_22867/3130990966.py:35: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_22867/3130990966.py:36: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 14:58:16.917406: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-02-09 14:58:16.950066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399965000 Hz\n",
      "2023-02-09 14:58:16.952973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x416f030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-09 14:58:16.953030: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-02-09 14:58:16.958511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./retrieve_model/model.ckpt-46878\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 14:58:21.263156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e214e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-09 14:58:21.263204: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-02-09 14:58:21.265666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:08:00.0\n",
      "2023-02-09 14:58:21.265949: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266063: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266168: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266271: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266425: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266589: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266743: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-09 14:58:21.266797: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-09 14:58:21.266852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-09 14:58:21.266904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2023-02-09 14:58:21.266941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 46878 into ./retrieve_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 389.53833, step = 46879\n",
      "INFO:tensorflow:global_step/sec: 212.134\n",
      "INFO:tensorflow:loss = 378.653, step = 46979 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.598\n",
      "INFO:tensorflow:loss = 365.52658, step = 47079 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.078\n",
      "INFO:tensorflow:loss = 367.5211, step = 47179 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.807\n",
      "INFO:tensorflow:loss = 392.0479, step = 47279 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.639\n",
      "INFO:tensorflow:loss = 383.17627, step = 47379 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.569\n",
      "INFO:tensorflow:loss = 379.45837, step = 47479 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.358\n",
      "INFO:tensorflow:loss = 389.31494, step = 47579 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.147\n",
      "INFO:tensorflow:loss = 358.67267, step = 47679 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.637\n",
      "INFO:tensorflow:loss = 375.98932, step = 47779 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.432\n",
      "INFO:tensorflow:loss = 396.47363, step = 47879 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.418\n",
      "INFO:tensorflow:loss = 362.22787, step = 47979 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.864\n",
      "INFO:tensorflow:loss = 389.5713, step = 48079 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.634\n",
      "INFO:tensorflow:loss = 381.27362, step = 48179 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.625\n",
      "INFO:tensorflow:loss = 382.2373, step = 48279 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.139\n",
      "INFO:tensorflow:loss = 377.46692, step = 48379 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.157\n",
      "INFO:tensorflow:loss = 373.68137, step = 48479 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.311\n",
      "INFO:tensorflow:loss = 359.4391, step = 48579 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.387\n",
      "INFO:tensorflow:loss = 359.63037, step = 48679 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.5\n",
      "INFO:tensorflow:loss = 381.44263, step = 48779 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.726\n",
      "INFO:tensorflow:loss = 357.29095, step = 48879 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.674\n",
      "INFO:tensorflow:loss = 353.06378, step = 48979 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.977\n",
      "INFO:tensorflow:loss = 374.82715, step = 49079 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.172\n",
      "INFO:tensorflow:loss = 355.32245, step = 49179 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.728\n",
      "INFO:tensorflow:loss = 362.46634, step = 49279 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.727\n",
      "INFO:tensorflow:loss = 388.3102, step = 49379 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.273\n",
      "INFO:tensorflow:loss = 371.17957, step = 49479 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.835\n",
      "INFO:tensorflow:loss = 361.72183, step = 49579 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.692\n",
      "INFO:tensorflow:loss = 374.9454, step = 49679 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.255\n",
      "INFO:tensorflow:loss = 374.93634, step = 49779 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.606\n",
      "INFO:tensorflow:loss = 374.48926, step = 49879 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.616\n",
      "INFO:tensorflow:loss = 364.9689, step = 49979 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.543\n",
      "INFO:tensorflow:loss = 371.62894, step = 50079 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.276\n",
      "INFO:tensorflow:loss = 351.24597, step = 50179 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.835\n",
      "INFO:tensorflow:loss = 379.08762, step = 50279 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 315\n",
      "INFO:tensorflow:loss = 353.38635, step = 50379 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.881\n",
      "INFO:tensorflow:loss = 362.85413, step = 50479 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.667\n",
      "INFO:tensorflow:loss = 343.21597, step = 50579 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.161\n",
      "INFO:tensorflow:loss = 364.08377, step = 50679 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.154\n",
      "INFO:tensorflow:loss = 373.93332, step = 50779 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.115\n",
      "INFO:tensorflow:loss = 362.86765, step = 50879 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.728\n",
      "INFO:tensorflow:loss = 383.9026, step = 50979 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.638\n",
      "INFO:tensorflow:loss = 386.91293, step = 51079 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.235\n",
      "INFO:tensorflow:loss = 350.04953, step = 51179 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.364\n",
      "INFO:tensorflow:loss = 373.43597, step = 51279 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.834\n",
      "INFO:tensorflow:loss = 358.11224, step = 51379 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.05\n",
      "INFO:tensorflow:loss = 384.53397, step = 51479 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.332\n",
      "INFO:tensorflow:loss = 365.46854, step = 51579 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.423\n",
      "INFO:tensorflow:loss = 366.53705, step = 51679 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.095\n",
      "INFO:tensorflow:loss = 350.08685, step = 51779 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.292\n",
      "INFO:tensorflow:loss = 356.83997, step = 51879 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.343\n",
      "INFO:tensorflow:loss = 381.2213, step = 51979 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.388\n",
      "INFO:tensorflow:loss = 381.2725, step = 52079 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.385\n",
      "INFO:tensorflow:loss = 364.78168, step = 52179 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.031\n",
      "INFO:tensorflow:loss = 368.86053, step = 52279 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.868\n",
      "INFO:tensorflow:loss = 367.17755, step = 52379 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.657\n",
      "INFO:tensorflow:loss = 371.97736, step = 52479 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.815\n",
      "INFO:tensorflow:loss = 374.062, step = 52579 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.363\n",
      "INFO:tensorflow:loss = 372.49963, step = 52679 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.063\n",
      "INFO:tensorflow:loss = 356.6819, step = 52779 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.127\n",
      "INFO:tensorflow:loss = 351.5174, step = 52879 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.69\n",
      "INFO:tensorflow:loss = 361.87994, step = 52979 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.278\n",
      "INFO:tensorflow:loss = 370.6008, step = 53079 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.669\n",
      "INFO:tensorflow:loss = 350.37567, step = 53179 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.818\n",
      "INFO:tensorflow:loss = 346.62726, step = 53279 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.098\n",
      "INFO:tensorflow:loss = 386.68475, step = 53379 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.087\n",
      "INFO:tensorflow:loss = 362.74677, step = 53479 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.009\n",
      "INFO:tensorflow:loss = 369.80603, step = 53579 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.866\n",
      "INFO:tensorflow:loss = 351.09097, step = 53679 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.372\n",
      "INFO:tensorflow:loss = 373.83795, step = 53779 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.083\n",
      "INFO:tensorflow:loss = 378.26974, step = 53879 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.319\n",
      "INFO:tensorflow:loss = 353.3589, step = 53979 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.586\n",
      "INFO:tensorflow:loss = 370.8758, step = 54079 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.993\n",
      "INFO:tensorflow:loss = 370.48077, step = 54179 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.47\n",
      "INFO:tensorflow:loss = 338.99026, step = 54279 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.083\n",
      "INFO:tensorflow:loss = 354.6768, step = 54379 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.225\n",
      "INFO:tensorflow:loss = 346.74414, step = 54479 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.648\n",
      "INFO:tensorflow:loss = 360.90796, step = 54579 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.57\n",
      "INFO:tensorflow:loss = 364.09253, step = 54679 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.554\n",
      "INFO:tensorflow:loss = 341.16275, step = 54779 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.861\n",
      "INFO:tensorflow:loss = 325.92914, step = 54879 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.888\n",
      "INFO:tensorflow:loss = 328.865, step = 54979 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.189\n",
      "INFO:tensorflow:loss = 328.6757, step = 55079 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.616\n",
      "INFO:tensorflow:loss = 340.9331, step = 55179 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.902\n",
      "INFO:tensorflow:loss = 339.16443, step = 55279 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.7\n",
      "INFO:tensorflow:loss = 343.47528, step = 55379 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.439\n",
      "INFO:tensorflow:loss = 347.75476, step = 55479 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.695\n",
      "INFO:tensorflow:loss = 355.78632, step = 55579 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.539\n",
      "INFO:tensorflow:loss = 335.1443, step = 55679 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.264\n",
      "INFO:tensorflow:loss = 335.12677, step = 55779 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.196\n",
      "INFO:tensorflow:loss = 341.06146, step = 55879 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.461\n",
      "INFO:tensorflow:loss = 331.1759, step = 55979 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.495\n",
      "INFO:tensorflow:loss = 337.00162, step = 56079 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.058\n",
      "INFO:tensorflow:loss = 336.76733, step = 56179 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.133\n",
      "INFO:tensorflow:loss = 327.0462, step = 56279 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.025\n",
      "INFO:tensorflow:loss = 342.01385, step = 56379 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.213\n",
      "INFO:tensorflow:loss = 335.28415, step = 56479 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.222\n",
      "INFO:tensorflow:loss = 335.82687, step = 56579 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.811\n",
      "INFO:tensorflow:loss = 326.46, step = 56679 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.799\n",
      "INFO:tensorflow:loss = 309.51898, step = 56779 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.183\n",
      "INFO:tensorflow:loss = 334.0635, step = 56879 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.725\n",
      "INFO:tensorflow:loss = 328.1302, step = 56979 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.705\n",
      "INFO:tensorflow:loss = 331.07306, step = 57079 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.8\n",
      "INFO:tensorflow:loss = 340.7549, step = 57179 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.267\n",
      "INFO:tensorflow:loss = 338.4006, step = 57279 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.765\n",
      "INFO:tensorflow:loss = 343.36978, step = 57379 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.519\n",
      "INFO:tensorflow:loss = 340.8421, step = 57479 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.614\n",
      "INFO:tensorflow:loss = 351.9361, step = 57579 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.961\n",
      "INFO:tensorflow:loss = 345.41534, step = 57679 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.427\n",
      "INFO:tensorflow:loss = 332.23938, step = 57779 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.521\n",
      "INFO:tensorflow:loss = 333.23203, step = 57879 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.572\n",
      "INFO:tensorflow:loss = 333.89853, step = 57979 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.992\n",
      "INFO:tensorflow:loss = 340.3675, step = 58079 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.704\n",
      "INFO:tensorflow:loss = 339.78082, step = 58179 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.308\n",
      "INFO:tensorflow:loss = 316.79596, step = 58279 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.449\n",
      "INFO:tensorflow:loss = 342.74646, step = 58379 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.311\n",
      "INFO:tensorflow:loss = 314.83923, step = 58479 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.749\n",
      "INFO:tensorflow:loss = 345.5288, step = 58579 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.478\n",
      "INFO:tensorflow:loss = 336.5243, step = 58679 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.368\n",
      "INFO:tensorflow:loss = 327.26868, step = 58779 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.728\n",
      "INFO:tensorflow:loss = 328.06677, step = 58879 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.826\n",
      "INFO:tensorflow:loss = 332.08084, step = 58979 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.581\n",
      "INFO:tensorflow:loss = 322.2138, step = 59079 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.138\n",
      "INFO:tensorflow:loss = 346.8099, step = 59179 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.058\n",
      "INFO:tensorflow:loss = 354.08002, step = 59279 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.597\n",
      "INFO:tensorflow:loss = 333.12476, step = 59379 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.609\n",
      "INFO:tensorflow:loss = 336.41458, step = 59479 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.11\n",
      "INFO:tensorflow:loss = 340.43387, step = 59579 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.482\n",
      "INFO:tensorflow:loss = 330.44827, step = 59679 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.557\n",
      "INFO:tensorflow:loss = 332.53687, step = 59779 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.174\n",
      "INFO:tensorflow:loss = 333.02582, step = 59879 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.318\n",
      "INFO:tensorflow:loss = 327.6556, step = 59979 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.195\n",
      "INFO:tensorflow:loss = 341.49585, step = 60079 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.38\n",
      "INFO:tensorflow:loss = 320.277, step = 60179 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.08\n",
      "INFO:tensorflow:loss = 327.20093, step = 60279 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.703\n",
      "INFO:tensorflow:loss = 319.90875, step = 60379 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.021\n",
      "INFO:tensorflow:loss = 333.40485, step = 60479 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.581\n",
      "INFO:tensorflow:loss = 315.03833, step = 60579 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.315\n",
      "INFO:tensorflow:loss = 323.99756, step = 60679 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.318\n",
      "INFO:tensorflow:loss = 334.0086, step = 60779 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.642\n",
      "INFO:tensorflow:loss = 337.66455, step = 60879 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.608\n",
      "INFO:tensorflow:loss = 320.72995, step = 60979 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.909\n",
      "INFO:tensorflow:loss = 317.51315, step = 61079 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.855\n",
      "INFO:tensorflow:loss = 337.34692, step = 61179 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.225\n",
      "INFO:tensorflow:loss = 337.5013, step = 61279 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.69\n",
      "INFO:tensorflow:loss = 319.99017, step = 61379 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.049\n",
      "INFO:tensorflow:loss = 332.3493, step = 61479 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.335\n",
      "INFO:tensorflow:loss = 341.732, step = 61579 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.39\n",
      "INFO:tensorflow:loss = 325.25354, step = 61679 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.46\n",
      "INFO:tensorflow:loss = 311.7577, step = 61779 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.39\n",
      "INFO:tensorflow:loss = 335.52063, step = 61879 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.861\n",
      "INFO:tensorflow:loss = 329.51044, step = 61979 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.634\n",
      "INFO:tensorflow:loss = 310.69705, step = 62079 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.931\n",
      "INFO:tensorflow:loss = 327.74066, step = 62179 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.771\n",
      "INFO:tensorflow:loss = 320.67548, step = 62279 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.61\n",
      "INFO:tensorflow:loss = 340.016, step = 62379 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.2\n",
      "INFO:tensorflow:loss = 340.26505, step = 62479 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.731\n",
      "INFO:tensorflow:loss = 332.63153, step = 62579 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.824\n",
      "INFO:tensorflow:loss = 322.18765, step = 62679 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.334\n",
      "INFO:tensorflow:loss = 328.5866, step = 62779 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.877\n",
      "INFO:tensorflow:loss = 315.6093, step = 62879 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.341\n",
      "INFO:tensorflow:loss = 306.20377, step = 62979 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.529\n",
      "INFO:tensorflow:loss = 304.66516, step = 63079 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.189\n",
      "INFO:tensorflow:loss = 284.58612, step = 63179 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.142\n",
      "INFO:tensorflow:loss = 307.72726, step = 63279 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.66\n",
      "INFO:tensorflow:loss = 326.0301, step = 63379 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.346\n",
      "INFO:tensorflow:loss = 309.64252, step = 63479 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.907\n",
      "INFO:tensorflow:loss = 318.29843, step = 63579 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.602\n",
      "INFO:tensorflow:loss = 306.49792, step = 63679 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.18\n",
      "INFO:tensorflow:loss = 321.16772, step = 63779 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.559\n",
      "INFO:tensorflow:loss = 300.15735, step = 63879 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.875\n",
      "INFO:tensorflow:loss = 324.21527, step = 63979 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.965\n",
      "INFO:tensorflow:loss = 320.08118, step = 64079 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.498\n",
      "INFO:tensorflow:loss = 314.34674, step = 64179 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.356\n",
      "INFO:tensorflow:loss = 334.16052, step = 64279 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.966\n",
      "INFO:tensorflow:loss = 330.06274, step = 64379 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.24\n",
      "INFO:tensorflow:loss = 315.30838, step = 64479 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.501\n",
      "INFO:tensorflow:loss = 312.4419, step = 64579 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.055\n",
      "INFO:tensorflow:loss = 333.75165, step = 64679 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.241\n",
      "INFO:tensorflow:loss = 330.84454, step = 64779 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.147\n",
      "INFO:tensorflow:loss = 302.45456, step = 64879 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.211\n",
      "INFO:tensorflow:loss = 319.8227, step = 64979 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.996\n",
      "INFO:tensorflow:loss = 320.5595, step = 65079 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.087\n",
      "INFO:tensorflow:loss = 338.203, step = 65179 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.973\n",
      "INFO:tensorflow:loss = 301.4944, step = 65279 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.538\n",
      "INFO:tensorflow:loss = 302.72458, step = 65379 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.83\n",
      "INFO:tensorflow:loss = 306.5716, step = 65479 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.072\n",
      "INFO:tensorflow:loss = 299.34973, step = 65579 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.556\n",
      "INFO:tensorflow:loss = 316.95538, step = 65679 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.844\n",
      "INFO:tensorflow:loss = 319.4176, step = 65779 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.961\n",
      "INFO:tensorflow:loss = 321.57068, step = 65879 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.341\n",
      "INFO:tensorflow:loss = 326.13135, step = 65979 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.846\n",
      "INFO:tensorflow:loss = 328.34198, step = 66079 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.223\n",
      "INFO:tensorflow:loss = 307.58942, step = 66179 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.023\n",
      "INFO:tensorflow:loss = 326.81958, step = 66279 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.042\n",
      "INFO:tensorflow:loss = 313.12286, step = 66379 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.725\n",
      "INFO:tensorflow:loss = 315.9563, step = 66479 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.222\n",
      "INFO:tensorflow:loss = 327.76575, step = 66579 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.865\n",
      "INFO:tensorflow:loss = 338.1674, step = 66679 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:loss = 310.27063, step = 66779 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.387\n",
      "INFO:tensorflow:loss = 304.95972, step = 66879 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.522\n",
      "INFO:tensorflow:loss = 321.51913, step = 66979 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.216\n",
      "INFO:tensorflow:loss = 321.44427, step = 67079 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.478\n",
      "INFO:tensorflow:loss = 312.73804, step = 67179 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.956\n",
      "INFO:tensorflow:loss = 327.53207, step = 67279 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.245\n",
      "INFO:tensorflow:loss = 303.42773, step = 67379 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.308\n",
      "INFO:tensorflow:loss = 318.49194, step = 67479 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.736\n",
      "INFO:tensorflow:loss = 314.38013, step = 67579 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.003\n",
      "INFO:tensorflow:loss = 313.84555, step = 67679 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.188\n",
      "INFO:tensorflow:loss = 318.72968, step = 67779 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.62\n",
      "INFO:tensorflow:loss = 315.01855, step = 67879 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.942\n",
      "INFO:tensorflow:loss = 306.65314, step = 67979 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.537\n",
      "INFO:tensorflow:loss = 310.40405, step = 68079 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.374\n",
      "INFO:tensorflow:loss = 303.65143, step = 68179 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.498\n",
      "INFO:tensorflow:loss = 329.99286, step = 68279 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.922\n",
      "INFO:tensorflow:loss = 328.00427, step = 68379 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.984\n",
      "INFO:tensorflow:loss = 307.8866, step = 68479 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.832\n",
      "INFO:tensorflow:loss = 311.4298, step = 68579 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.497\n",
      "INFO:tensorflow:loss = 323.4454, step = 68679 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.673\n",
      "INFO:tensorflow:loss = 290.64838, step = 68779 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.555\n",
      "INFO:tensorflow:loss = 307.9375, step = 68879 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.376\n",
      "INFO:tensorflow:loss = 322.9468, step = 68979 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.027\n",
      "INFO:tensorflow:loss = 323.39966, step = 69079 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.686\n",
      "INFO:tensorflow:loss = 322.31573, step = 69179 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.777\n",
      "INFO:tensorflow:loss = 323.78662, step = 69279 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.594\n",
      "INFO:tensorflow:loss = 299.66608, step = 69379 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.616\n",
      "INFO:tensorflow:loss = 307.89673, step = 69479 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.586\n",
      "INFO:tensorflow:loss = 313.76596, step = 69579 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.648\n",
      "INFO:tensorflow:loss = 316.72864, step = 69679 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.21\n",
      "INFO:tensorflow:loss = 318.41962, step = 69779 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.303\n",
      "INFO:tensorflow:loss = 313.5545, step = 69879 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.92\n",
      "INFO:tensorflow:loss = 304.4912, step = 69979 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.233\n",
      "INFO:tensorflow:loss = 311.7636, step = 70079 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.305\n",
      "INFO:tensorflow:loss = 302.42828, step = 70179 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.186\n",
      "INFO:tensorflow:loss = 318.23376, step = 70279 (0.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 70317 into ./retrieve_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 111.82228.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f2f681a9a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_model = tf.estimator.Estimator(model_fn=model_fn, model_dir='./retrieve_model')\n",
    "retrieval_model.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export embeddings\n",
    "\n",
    "After the retrieval model is trained, we need to export all the query and item embeddings with the trained parameters. With Tensorflow Estimator framework, this can be done easily by constructing another *input_fn* to feed all the data to the model and grab the predictions once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieval_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35311/2370379497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mquery_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mitem_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieval_model' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({'query': np.arange(VOCAB_SIZE), 'item': np.arange(VOCAB_SIZE)})\n",
    "    dataset = dataset.batch(VOCAB_SIZE)\n",
    "    return dataset\n",
    "\n",
    "results = list(retrieval_model.predict(input_fn=predict_input_fn))\n",
    "query_emb = np.stack([r['query'] for r in results], axis=0)\n",
    "item_emb = np.stack([r['item'] for r in results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/query_emb.npy', query_emb)\n",
    "np.save('./data/item_emb.npy', item_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuanrz/miniconda3/envs/torch1.9/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = np.load('./data/query_emb.npy')\n",
    "item_emb = np.load('./data/item_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_norm = torch.nn.functional.normalize(torch.tensor(query_emb), p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1024, -0.0735, -0.0899,  0.0190,  0.0833, -0.0045, -0.1742,  0.1705,\n",
       "         0.1849,  0.1854, -0.2887,  0.0201, -0.1863,  0.0487,  0.0322, -0.1010,\n",
       "        -0.0838,  0.0083,  0.2286,  0.1472,  0.0049,  0.1628, -0.0871,  0.0269,\n",
       "         0.0526,  0.0511, -0.2437,  0.1787, -0.0423,  0.0207,  0.2389, -0.0704,\n",
       "        -0.0608,  0.1463, -0.2012, -0.1345, -0.0100,  0.0452,  0.0235, -0.0113,\n",
       "         0.0050, -0.1005, -0.0125, -0.1183, -0.1659,  0.1518,  0.0426,  0.1222,\n",
       "        -0.0601,  0.1255,  0.1356, -0.0433,  0.1330,  0.0824, -0.2870,  0.0395,\n",
       "        -0.0584, -0.1328,  0.2278, -0.0669, -0.0675,  0.1167, -0.0666,  0.0755])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_norm2 = query_emb / np.linalg.norm(query_emb, ord=2, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10241943, -0.07352483, -0.08994059,  0.01903564,  0.08332656,\n",
       "       -0.00453188, -0.17419763,  0.17049815,  0.18494225,  0.1854223 ,\n",
       "       -0.2886851 ,  0.0200959 , -0.18626961,  0.04869973,  0.03217772,\n",
       "       -0.10100898, -0.08377016,  0.00828866,  0.22862867,  0.14716628,\n",
       "        0.00486718,  0.162839  , -0.08708248,  0.02692058,  0.05261027,\n",
       "        0.05111469, -0.24366027,  0.1786856 , -0.0422966 ,  0.02070607,\n",
       "        0.23886909, -0.07043963, -0.06076782,  0.14626878, -0.20122978,\n",
       "       -0.13448322, -0.0100024 ,  0.04517439,  0.02345273, -0.01131734,\n",
       "        0.00497423, -0.10047087, -0.01251143, -0.11829784, -0.16593523,\n",
       "        0.15178622,  0.04259186,  0.12220024, -0.06010552,  0.12549165,\n",
       "        0.13559249, -0.04334374,  0.13296713,  0.08239124, -0.28702247,\n",
       "        0.03951252, -0.0583694 , -0.13283312,  0.22781931, -0.06694355,\n",
       "       -0.06747849,  0.11667447, -0.06663574,  0.07553485], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_norm2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute force search\n",
    "\n",
    "Before we try approximate nearest neighbor (ANN) search algorithms, let's first do a brute force search to get the upper bound of the retrieval accuracy. Theoretically, any ANN search algorithms should be much faster than Brute Force method but somewhat worse in retrieval accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_search(query_id, items, k=10):\n",
    "    query = query_emb[query_id:(query_id+1), :]\n",
    "    query_norm = np.linalg.norm(query, axis=1, keepdims=True)\n",
    "    item_norm = np.linalg.norm(items, axis=1, keepdims=True)\n",
    "    # query_norm = query / np.linalg.norm(query, axis=1, keepdims=True)\n",
    "    # item_norm = items / np.linalg.norm(items, axis=1, keepdims=True)\n",
    "    # print(item_norm.shape)\n",
    "    cos = np.matmul(query, np.transpose(items)) / query_norm / np.transpose(item_norm)\n",
    "    cos = cos.flatten()\n",
    "    sorted_item_id = np.argsort(-cos)\n",
    "    return sorted_item_id[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have quick look at the retrieval results. Note that the retrieved item IDs all have the two digits, 8 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6898, 8989, 8589, 3889, 9884, 9869, 9488, 9849, 2988, 9485])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force_search(98, item_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute a comprehensive retrieval accuracy called precision@k, where we use k=100. This metric measures that for the top 100 retrieved items, how much percentage of them are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(search_fn, query_id, items, k=100):\n",
    "    nn_items = search_fn(query_id, items, k=k)\n",
    "    \n",
    "    d, c, b, a = nn_items % 10, (nn_items // 10) % 10, (nn_items // 100) % 10, (nn_items // 1000) % 10\n",
    "    abcd = np.stack([a, b, c, d], axis=1)\n",
    "    y, x = query_id % 10, (query_id // 10) % 10\n",
    "    # check if x and y can be drawn from abcd without replacement\n",
    "    match = np.sum(np.logical_or(x == abcd, y == abcd), axis=1) >= 2 \n",
    "    precision = np.sum(match) / k\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall precision@100 =  0.9986279999999998\n"
     ]
    }
   ],
   "source": [
    "precision_at_100 = [precision_at_k(brute_force_search, i, item_emb, k=100) for i in range(VOCAB_SIZE)]\n",
    "print(\"overall precision@100 = \", np.mean(precision_at_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_norm = query_emb / np.linalg.norm(query_emb, ord=2, axis=1, keepdims=True)\n",
    "item_norm = item_emb / np.linalg.norm(item_emb, ord=2, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = hnswlib.Index(space = 'cosine', dim=EMB_DIM)\n",
    "p = hnswlib.Index(space = 'l2', dim=EMB_DIM)\n",
    "p.init_index(max_elements = N, ef_construction=100, M=16)\n",
    "p.set_ef(10)\n",
    "p.set_num_threads(4)\n",
    "p.add_items(item_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hnsw_search(query_id, items, k=10):\n",
    "    query = query_norm[query_id:(query_id+1), :]\n",
    "    item_ids, _ = p.knn_query(query, k=k)\n",
    "    return item_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall precision@100 =  0.9999\n"
     ]
    }
   ],
   "source": [
    "precision_at_100 = [precision_at_k(hnsw_search, i, None, k=100) for i in range(VOCAB_SIZE)]\n",
    "print(\"overall precision@100 = \", np.mean(precision_at_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faiss search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try Faiss, which is a widely used ANN library developed by Facebook. It is based on Product Quantization techniques. Here we set our index type to be 'IVF8,PQ8', which means coarse quantization into *8* clusters and then product quantization into *8* segments, each of which is represented by *one* byte, or *2^8 = 256* subvectors.\n",
    "\n",
    "First, we need to build an embedding index with all the item embeddings. Note that we need to first normalize all item embeddings before building the index with *inner product* as distance metric, or more precisely, inverse distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.index_factory(EMB_DIM, 'IVF8,PQ8', faiss.METRIC_INNER_PRODUCT)\n",
    "item_emb = item_emb / np.linalg.norm(item_emb, axis=1, keepdims=True)\n",
    "index.train(item_emb)\n",
    "index.add(item_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_search(query_id, items, k=10):\n",
    "    query = query_emb[query_id:(query_id+1), :]\n",
    "    D, I = index.search(query, k)\n",
    "    D, I = D.flatten(), I.flatten()\n",
    "    return I[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall precision@100 =  0.961116\n"
     ]
    }
   ],
   "source": [
    "precision_at_100 = [precision_at_k(faiss_search, i, item_emb, k=100) for i in range(VOCAB_SIZE)]\n",
    "print(\"overall precision@100 = \", np.mean(precision_at_100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poeem search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from above separately built embedding index, *poeem* learns the embedding model jointly with embedding index. Thus, there is no extra index building step. But we need to make some simple changes into the above *model_fn* function to adopt *poeem* indexing layer.\n",
    "\n",
    "Note that we only need to make changes at three places, marked by ### [poeem code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poeem_model_fn(features, labels, mode, params):\n",
    "    query_column = tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='query',\n",
    "            vocabulary_list=range(VOCAB_SIZE),\n",
    "            dtype=tf.int32),\n",
    "        dimension=EMB_DIM)\n",
    "    query_emb = tf.feature_column.input_layer(features, [query_column])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        ### [poeem code] directly do ANN search in the model as a TensorFlow op.\n",
    "        if params.get('item_search', False):\n",
    "            index = poeem.search.index_from_file(params['index_file'])\n",
    "            neighbors, scores = index.search(\n",
    "                tf.expand_dims(query_emb, 1),\n",
    "                params['topk'],\n",
    "                params['nprobe'],\n",
    "                params['metric_type'],\n",
    "                verbose=False)        \n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, predictions={'neighbors': neighbors, 'scores': scores})\n",
    "        ### end [poeem code]\n",
    "        \n",
    "    item_column = tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='item',\n",
    "            vocabulary_list=range(VOCAB_SIZE),\n",
    "            dtype=tf.int32),\n",
    "        dimension=EMB_DIM)\n",
    "    item_emb = tf.feature_column.input_layer(features, [item_column])\n",
    "    item_emb = tf.nn.l2_normalize(item_emb, axis=1)\n",
    "    \n",
    "\n",
    "    ### [poeem code] item indexing layer as the last layer in item tower\n",
    "    hparams = poeem.embedding.PoeemHparam(coarse_K=8,\n",
    "                                          K=256,\n",
    "                                          D=8,\n",
    "                                          rotate=0) # exactly the same parameters as Faiss, specified above.\n",
    "    item_batch_quantized = poeem.embedding.PoeemEmbed(\n",
    "        EMB_DIM,\n",
    "        warmup_steps=16384,\n",
    "        buffer_size=8192,\n",
    "        hparams=hparams,\n",
    "        mode=mode)\n",
    "    \n",
    "    # gradient straight-through estimator. For details, check out our paper.\n",
    "    item_emb_tau, coarse_code, code, regularizer = item_batch_quantized.forward(item_emb)\n",
    "    item_emb = item_emb - tf.stop_gradient(item_emb - item_emb_tau)\n",
    "    ### end [poeem code] \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        ### [poeem code] exprt item embeddings/PQ code for disk persistency.\n",
    "        if params.get('item_predict', False):\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, predictions={\n",
    "                    'item_coarse_code': coarse_code,\n",
    "                    'item_code': code,\n",
    "                    'item_norm': tf.norm(item_emb, axis=1)\n",
    "                })\n",
    "        ### end [poeem code] \n",
    "\n",
    "    def cosine(a, b):\n",
    "        a = tf.nn.l2_normalize(a, axis=1)\n",
    "        b = tf.nn.l2_normalize(b, axis=1)\n",
    "        return tf.matmul(a, b, transpose_b=True)\n",
    "\n",
    "    scores = cosine(query_emb, item_emb)\n",
    "\n",
    "    batch_size = tf.shape(query_emb)[0]\n",
    "    loss = tf.reduce_sum(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=tf.eye(batch_size),\n",
    "            logits=scores * 30))\n",
    "    \n",
    "    loss = loss + regularizer\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(LEARNING_RATE)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, train_op=train_op, predictions={'query': query_emb, 'item': item_emb})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './poeem_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f901f8c3cd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_37520/909220440.py:8: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3182: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3122: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/embedding_ops.py:802: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:316: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:244: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:95: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:332: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:338: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:342: The name tf.scatter_add is deprecated. Please use tf.compat.v1.scatter_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:342: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/python/embedding.py:343: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_37520/909220440.py:77: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:20:17.456944: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-02-08 20:20:17.486003: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399965000 Hz\n",
      "2023-02-08 20:20:17.489437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1242c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 20:20:17.489509: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-02-08 20:20:17.494234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:20:19.493871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43f8f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 20:20:19.493948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-02-08 20:20:19.493962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-02-08 20:20:19.493973: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-02-08 20:20:19.493984: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2023-02-08 20:20:19.513571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:04:00.0\n",
      "2023-02-08 20:20:19.515819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:05:00.0\n",
      "2023-02-08 20:20:19.517956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:08:00.0\n",
      "2023-02-08 20:20:19.518880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:85:00.0\n",
      "2023-02-08 20:20:19.519122: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519228: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519323: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519418: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519510: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519603: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519699: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:20:19.519712: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-08 20:20:19.519768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-08 20:20:19.519781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 \n",
      "2023-02-08 20:20:19.519789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y N \n",
      "2023-02-08 20:20:19.519795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y N \n",
      "2023-02-08 20:20:19.519800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N N \n",
      "2023-02-08 20:20:19.519805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N N N \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./poeem_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1334.2151, step = 1\n",
      "INFO:tensorflow:global_step/sec: 147.884\n",
      "INFO:tensorflow:loss = 1322.4939, step = 101 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.175\n",
      "INFO:tensorflow:loss = 1300.1631, step = 201 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.458\n",
      "INFO:tensorflow:loss = 1375.9381, step = 301 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.084\n",
      "INFO:tensorflow:loss = 1374.4829, step = 401 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.627\n",
      "INFO:tensorflow:loss = 1325.1431, step = 501 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.307\n",
      "INFO:tensorflow:loss = 1358.9294, step = 601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.543\n",
      "INFO:tensorflow:loss = 1344.8783, step = 701 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.012\n",
      "INFO:tensorflow:loss = 1297.4072, step = 801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.544\n",
      "INFO:tensorflow:loss = 1308.1035, step = 901 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.766\n",
      "INFO:tensorflow:loss = 1256.9545, step = 1001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.578\n",
      "INFO:tensorflow:loss = 1334.0831, step = 1101 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.837\n",
      "INFO:tensorflow:loss = 1379.7146, step = 1201 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.707\n",
      "INFO:tensorflow:loss = 1295.1206, step = 1301 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.458\n",
      "INFO:tensorflow:loss = 1307.1293, step = 1401 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.693\n",
      "INFO:tensorflow:loss = 1246.706, step = 1501 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.638\n",
      "INFO:tensorflow:loss = 1221.2178, step = 1601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.81\n",
      "INFO:tensorflow:loss = 1199.7799, step = 1701 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.481\n",
      "INFO:tensorflow:loss = 1298.6536, step = 1801 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.428\n",
      "INFO:tensorflow:loss = 1121.5343, step = 1901 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.79\n",
      "INFO:tensorflow:loss = 1162.5348, step = 2001 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.873\n",
      "INFO:tensorflow:loss = 1281.1147, step = 2101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.754\n",
      "INFO:tensorflow:loss = 1205.0449, step = 2201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.601\n",
      "INFO:tensorflow:loss = 1185.221, step = 2301 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.419\n",
      "INFO:tensorflow:loss = 1192.3704, step = 2401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.083\n",
      "INFO:tensorflow:loss = 1117.0836, step = 2501 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.394\n",
      "INFO:tensorflow:loss = 1131.9191, step = 2601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.921\n",
      "INFO:tensorflow:loss = 1212.4076, step = 2701 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.49\n",
      "INFO:tensorflow:loss = 1143.8337, step = 2801 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.068\n",
      "INFO:tensorflow:loss = 1059.8167, step = 2901 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.882\n",
      "INFO:tensorflow:loss = 1060.1807, step = 3001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.874\n",
      "INFO:tensorflow:loss = 1129.9445, step = 3101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.265\n",
      "INFO:tensorflow:loss = 1012.6299, step = 3201 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.118\n",
      "INFO:tensorflow:loss = 1117.7236, step = 3301 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.215\n",
      "INFO:tensorflow:loss = 980.81555, step = 3401 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.157\n",
      "INFO:tensorflow:loss = 980.72626, step = 3501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.51\n",
      "INFO:tensorflow:loss = 1082.2692, step = 3601 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.264\n",
      "INFO:tensorflow:loss = 1004.41547, step = 3701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.167\n",
      "INFO:tensorflow:loss = 1015.80176, step = 3801 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.638\n",
      "INFO:tensorflow:loss = 970.98224, step = 3901 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.415\n",
      "INFO:tensorflow:loss = 996.9663, step = 4001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.839\n",
      "INFO:tensorflow:loss = 985.425, step = 4101 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.146\n",
      "INFO:tensorflow:loss = 928.0553, step = 4201 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.107\n",
      "INFO:tensorflow:loss = 943.7715, step = 4301 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.607\n",
      "INFO:tensorflow:loss = 917.137, step = 4401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.47\n",
      "INFO:tensorflow:loss = 912.906, step = 4501 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.454\n",
      "INFO:tensorflow:loss = 916.2721, step = 4601 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.803\n",
      "INFO:tensorflow:loss = 914.9295, step = 4701 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.757\n",
      "INFO:tensorflow:loss = 939.88245, step = 4801 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.641\n",
      "INFO:tensorflow:loss = 874.4845, step = 4901 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.698\n",
      "INFO:tensorflow:loss = 867.189, step = 5001 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.021\n",
      "INFO:tensorflow:loss = 916.0381, step = 5101 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.816\n",
      "INFO:tensorflow:loss = 894.9643, step = 5201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.372\n",
      "INFO:tensorflow:loss = 758.5153, step = 5301 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.772\n",
      "INFO:tensorflow:loss = 776.39404, step = 5401 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.393\n",
      "INFO:tensorflow:loss = 877.88135, step = 5501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.996\n",
      "INFO:tensorflow:loss = 788.37805, step = 5601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.479\n",
      "INFO:tensorflow:loss = 801.9656, step = 5701 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.596\n",
      "INFO:tensorflow:loss = 862.35034, step = 5801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.22\n",
      "INFO:tensorflow:loss = 806.7241, step = 5901 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.363\n",
      "INFO:tensorflow:loss = 722.09595, step = 6001 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.777\n",
      "INFO:tensorflow:loss = 769.2715, step = 6101 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.384\n",
      "INFO:tensorflow:loss = 780.067, step = 6201 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.812\n",
      "INFO:tensorflow:loss = 743.97437, step = 6301 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.434\n",
      "INFO:tensorflow:loss = 737.1832, step = 6401 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.515\n",
      "INFO:tensorflow:loss = 743.9381, step = 6501 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.296\n",
      "INFO:tensorflow:loss = 812.8235, step = 6601 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.308\n",
      "INFO:tensorflow:loss = 692.905, step = 6701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.818\n",
      "INFO:tensorflow:loss = 694.03357, step = 6801 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.115\n",
      "INFO:tensorflow:loss = 703.2285, step = 6901 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.522\n",
      "INFO:tensorflow:loss = 750.2854, step = 7001 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.747\n",
      "INFO:tensorflow:loss = 696.95935, step = 7101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.925\n",
      "INFO:tensorflow:loss = 710.57587, step = 7201 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.189\n",
      "INFO:tensorflow:loss = 709.6793, step = 7301 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.197\n",
      "INFO:tensorflow:loss = 717.3396, step = 7401 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.041\n",
      "INFO:tensorflow:loss = 700.6103, step = 7501 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.95\n",
      "INFO:tensorflow:loss = 670.6609, step = 7601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.065\n",
      "INFO:tensorflow:loss = 678.80853, step = 7701 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.312\n",
      "INFO:tensorflow:loss = 697.3629, step = 7801 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.585\n",
      "INFO:tensorflow:loss = 233.81688, step = 7901 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.146\n",
      "INFO:tensorflow:loss = 237.77956, step = 8001 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.318\n",
      "INFO:tensorflow:loss = 267.1037, step = 8101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.72\n",
      "INFO:tensorflow:loss = 265.59338, step = 8201 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.453\n",
      "INFO:tensorflow:loss = 252.40836, step = 8301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.644\n",
      "INFO:tensorflow:loss = 337.4798, step = 8401 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.211\n",
      "INFO:tensorflow:loss = 336.50165, step = 8501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.933\n",
      "INFO:tensorflow:loss = 385.2756, step = 8601 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.092\n",
      "INFO:tensorflow:loss = 356.16443, step = 8701 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.11\n",
      "INFO:tensorflow:loss = 369.7716, step = 8801 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.977\n",
      "INFO:tensorflow:loss = 423.14777, step = 8901 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.853\n",
      "INFO:tensorflow:loss = 408.36218, step = 9001 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.538\n",
      "INFO:tensorflow:loss = 462.79886, step = 9101 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.787\n",
      "INFO:tensorflow:loss = 440.2014, step = 9201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.695\n",
      "INFO:tensorflow:loss = 402.36353, step = 9301 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.648\n",
      "INFO:tensorflow:loss = 379.12305, step = 9401 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.037\n",
      "INFO:tensorflow:loss = 424.44006, step = 9501 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.941\n",
      "INFO:tensorflow:loss = 429.64246, step = 9601 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.755\n",
      "INFO:tensorflow:loss = 434.57983, step = 9701 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.369\n",
      "INFO:tensorflow:loss = 412.95184, step = 9801 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.637\n",
      "INFO:tensorflow:loss = 376.7204, step = 9901 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.111\n",
      "INFO:tensorflow:loss = 424.6728, step = 10001 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.359\n",
      "INFO:tensorflow:loss = 400.73633, step = 10101 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.707\n",
      "INFO:tensorflow:loss = 435.20837, step = 10201 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.627\n",
      "INFO:tensorflow:loss = 406.37662, step = 10301 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 248\n",
      "INFO:tensorflow:loss = 470.27716, step = 10401 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.687\n",
      "INFO:tensorflow:loss = 426.37836, step = 10501 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.99\n",
      "INFO:tensorflow:loss = 477.92322, step = 10601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.382\n",
      "INFO:tensorflow:loss = 472.24734, step = 10701 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.172\n",
      "INFO:tensorflow:loss = 475.39795, step = 10801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.879\n",
      "INFO:tensorflow:loss = 457.25928, step = 10901 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.675\n",
      "INFO:tensorflow:loss = 396.13043, step = 11001 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.816\n",
      "INFO:tensorflow:loss = 464.9958, step = 11101 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.364\n",
      "INFO:tensorflow:loss = 469.39557, step = 11201 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.625\n",
      "INFO:tensorflow:loss = 422.2221, step = 11301 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.875\n",
      "INFO:tensorflow:loss = 414.50952, step = 11401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.351\n",
      "INFO:tensorflow:loss = 473.09625, step = 11501 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.953\n",
      "INFO:tensorflow:loss = 506.46243, step = 11601 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.882\n",
      "INFO:tensorflow:loss = 441.22986, step = 11701 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.924\n",
      "INFO:tensorflow:loss = 421.90686, step = 11801 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.626\n",
      "INFO:tensorflow:loss = 520.0383, step = 11901 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.92\n",
      "INFO:tensorflow:loss = 505.34427, step = 12001 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.231\n",
      "INFO:tensorflow:loss = 486.4607, step = 12101 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.43\n",
      "INFO:tensorflow:loss = 466.08813, step = 12201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.627\n",
      "INFO:tensorflow:loss = 462.16663, step = 12301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.145\n",
      "INFO:tensorflow:loss = 426.2265, step = 12401 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.083\n",
      "INFO:tensorflow:loss = 486.97452, step = 12501 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.122\n",
      "INFO:tensorflow:loss = 432.7357, step = 12601 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.965\n",
      "INFO:tensorflow:loss = 480.97717, step = 12701 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.393\n",
      "INFO:tensorflow:loss = 465.98267, step = 12801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.91\n",
      "INFO:tensorflow:loss = 432.82983, step = 12901 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.562\n",
      "INFO:tensorflow:loss = 446.19022, step = 13001 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.073\n",
      "INFO:tensorflow:loss = 426.0219, step = 13101 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.481\n",
      "INFO:tensorflow:loss = 435.69138, step = 13201 (0.416 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13289 vs previous value: 13289. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 246.31\n",
      "INFO:tensorflow:loss = 486.451, step = 13301 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.729\n",
      "INFO:tensorflow:loss = 423.54907, step = 13401 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.456\n",
      "INFO:tensorflow:loss = 437.10245, step = 13501 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.025\n",
      "INFO:tensorflow:loss = 401.16577, step = 13601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.555\n",
      "INFO:tensorflow:loss = 466.34143, step = 13701 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.745\n",
      "INFO:tensorflow:loss = 462.4102, step = 13801 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.903\n",
      "INFO:tensorflow:loss = 470.3158, step = 13901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.897\n",
      "INFO:tensorflow:loss = 476.60608, step = 14001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.775\n",
      "INFO:tensorflow:loss = 458.687, step = 14101 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.412\n",
      "INFO:tensorflow:loss = 435.4975, step = 14201 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.314\n",
      "INFO:tensorflow:loss = 456.453, step = 14301 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.283\n",
      "INFO:tensorflow:loss = 470.35303, step = 14401 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.367\n",
      "INFO:tensorflow:loss = 435.3216, step = 14501 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.174\n",
      "INFO:tensorflow:loss = 465.2262, step = 14601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.07\n",
      "INFO:tensorflow:loss = 414.94473, step = 14701 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.642\n",
      "INFO:tensorflow:loss = 441.6518, step = 14801 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.568\n",
      "INFO:tensorflow:loss = 420.32825, step = 14901 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.371\n",
      "INFO:tensorflow:loss = 438.59903, step = 15001 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.008\n",
      "INFO:tensorflow:loss = 420.40775, step = 15101 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.066\n",
      "INFO:tensorflow:loss = 429.87292, step = 15201 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.512\n",
      "INFO:tensorflow:loss = 393.0045, step = 15301 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.412\n",
      "INFO:tensorflow:loss = 403.67056, step = 15401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.659\n",
      "INFO:tensorflow:loss = 451.64697, step = 15501 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.077\n",
      "INFO:tensorflow:loss = 451.74084, step = 15601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.14\n",
      "INFO:tensorflow:loss = 203.31506, step = 15701 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.968\n",
      "INFO:tensorflow:loss = 237.63608, step = 15801 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.8\n",
      "INFO:tensorflow:loss = 240.38908, step = 15901 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.493\n",
      "INFO:tensorflow:loss = 231.93616, step = 16001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.224\n",
      "INFO:tensorflow:loss = 240.31644, step = 16101 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.773\n",
      "INFO:tensorflow:loss = 277.7642, step = 16201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.588\n",
      "INFO:tensorflow:loss = 270.17365, step = 16301 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.124\n",
      "INFO:tensorflow:loss = 262.19086, step = 16401 (0.405 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:21:28.948156: I cpp/clustering_raw_op.cc:128] Converged at iter 55 : average distance = 0.925711, assignment changed = 79 (0.00964355), assignment frequency histogram = (873, 1) (907, 1) (940, 1) (957, 1) (997, 1) (1029, 1) (1034, 1) (1455, 1) \n",
      "2023-02-08 20:21:28.990714: I cpp/clustering_raw_op.cc:128] Converged at iter 21 : average distance = 0.177143, assignment changed = 71 (0.00866699), assignment frequency histogram = (4, 1) (14, 1) (16, 1) (18, 1) (19, 1) (20, 2) (22, 1) (23, 1) (24, 3) (25, 1) (26, 3) (27, 2) (28, 3) (29, 3) (30, 4) (31, 3) (32, 8) (33, 8) (34, 6) (35, 7) (36, 9) (37, 11) (38, 18) (39, 8) (40, 6) (41, 12) (42, 10) (43, 8) (44, 7) (45, 3) (46, 11) (47, 7) (48, 6) (49, 4) (50, 4) (51, 4) (52, 3) (53, 4) (54, 2) (55, 3) (56, 1) (57, 1) (59, 3) (64, 1) (70, 1) \n",
      "2023-02-08 20:21:29.006979: I cpp/clustering_raw_op.cc:128] Converged at iter 28 : average distance = 0.174805, assignment changed = 81 (0.0098877), assignment frequency histogram = (2, 1) (10, 1) (19, 1) (20, 1) (22, 2) (23, 2) (24, 4) (25, 5) (26, 7) (27, 2) (28, 2) (29, 2) (30, 5) (31, 11) (32, 5) (33, 5) (34, 6) (35, 9) (36, 9) (37, 11) (38, 8) (39, 5) (40, 6) (41, 6) (42, 6) (43, 10) (44, 6) (45, 8) (46, 3) (47, 6) (48, 2) (49, 7) (50, 3) (51, 4) (52, 6) (53, 4) (54, 9) (55, 1) (56, 3) (57, 1) (58, 2) (59, 2) (62, 1) (63, 1) (64, 1) (65, 1) (66, 2) \n",
      "2023-02-08 20:21:29.050892: I cpp/clustering_raw_op.cc:128] Converged at iter 29 : average distance = 0.17832, assignment changed = 71 (0.00866699), assignment frequency histogram = (5, 1) (10, 2) (13, 1) (17, 1) (19, 2) (22, 2) (23, 1) (24, 1) (25, 4) (26, 1) (27, 5) (28, 3) (29, 5) (30, 7) (31, 2) (32, 6) (33, 5) (34, 3) (35, 4) (36, 7) (37, 10) (38, 14) (39, 12) (40, 10) (41, 8) (42, 4) (43, 8) (44, 8) (45, 7) (46, 8) (47, 5) (48, 7) (49, 3) (50, 3) (51, 7) (52, 5) (53, 2) (54, 4) (55, 5) (56, 2) (58, 4) (59, 2) (60, 1) (62, 1) (84, 1) \n",
      "2023-02-08 20:21:29.090649: I cpp/clustering_raw_op.cc:128] Converged at iter 38 : average distance = 0.172074, assignment changed = 68 (0.00830078), assignment frequency histogram = (2, 1) (8, 1) (10, 1) (20, 2) (21, 4) (22, 3) (23, 2) (24, 2) (25, 1) (26, 4) (27, 3) (28, 3) (29, 3) (30, 6) (31, 8) (32, 8) (33, 6) (34, 9) (35, 9) (36, 5) (37, 5) (38, 10) (39, 13) (40, 4) (41, 10) (42, 8) (43, 4) (44, 9) (45, 8) (46, 3) (47, 8) (48, 5) (49, 2) (50, 11) (51, 4) (52, 4) (53, 1) (54, 6) (55, 2) (56, 3) (59, 1) (60, 2) (62, 1) (64, 1) (68, 1) (76, 1) \n",
      "2023-02-08 20:21:29.149267: I cpp/clustering_raw_op.cc:128] Converged at iter 48 : average distance = 0.17616, assignment changed = 81 (0.0098877), assignment frequency histogram = (3, 1) (7, 1) (12, 1) (15, 1) (17, 1) (18, 1) (21, 2) (22, 3) (23, 1) (24, 5) (25, 4) (26, 6) (27, 8) (28, 5) (29, 10) (30, 5) (31, 14) (32, 8) (33, 8) (34, 9) (35, 9) (36, 9) (37, 8) (38, 10) (39, 14) (40, 9) (41, 3) (42, 8) (43, 10) (44, 9) (45, 4) (46, 4) (47, 6) (48, 5) (49, 3) (50, 4) (51, 2) (52, 1) (53, 4) (55, 4) (56, 1) (58, 1) (59, 2) \n",
      "2023-02-08 20:21:29.160197: I cpp/clustering_raw_op.cc:128] Converged at iter 50 : average distance = 0.175203, assignment changed = 74 (0.0090332), assignment frequency histogram = (1, 1) (11, 1) (12, 1) (13, 1) (15, 1) (19, 1) (20, 1) (21, 2) (22, 1) (23, 1) (24, 1) (25, 3) (26, 2) (27, 2) (28, 7) (29, 5) (30, 9) (31, 5) (32, 7) (33, 7) (34, 5) (35, 7) (36, 10) (37, 9) (38, 8) (39, 11) (40, 6) (41, 7) (42, 9) (43, 8) (44, 7) (45, 5) (46, 5) (47, 9) (48, 8) (49, 4) (50, 4) (51, 1) (52, 4) (53, 6) (54, 1) (55, 3) (57, 1) (58, 3) (59, 2) (60, 1) (63, 1) (64, 2) (66, 1) (70, 1) \n",
      "2023-02-08 20:21:29.240422: I cpp/clustering_raw_op.cc:128] Converged at iter 70 : average distance = 0.170731, assignment changed = 78 (0.00952148), assignment frequency histogram = (11, 2) (13, 1) (17, 1) (18, 1) (19, 2) (20, 3) (21, 3) (22, 6) (23, 2) (24, 7) (25, 7) (26, 6) (27, 11) (28, 10) (29, 13) (30, 10) (31, 10) (32, 13) (33, 12) (34, 12) (35, 9) (36, 4) (37, 9) (38, 8) (39, 13) (40, 8) (41, 6) (42, 12) (43, 3) (44, 5) (45, 6) (46, 4) (47, 5) (48, 2) (49, 2) (50, 2) (51, 1) (52, 1) (53, 1) (54, 1) (55, 2) (57, 1) (58, 1) (60, 1) \n",
      "2023-02-08 20:21:29.272519: I cpp/clustering_raw_op.cc:128] Converged at iter 92 : average distance = 0.169265, assignment changed = 74 (0.0090332), assignment frequency histogram = (13, 1) (16, 1) (17, 2) (18, 4) (19, 6) (20, 3) (21, 8) (22, 6) (23, 7) (24, 7) (25, 7) (26, 11) (27, 14) (28, 11) (29, 11) (30, 9) (31, 18) (32, 9) (33, 12) (34, 15) (35, 16) (36, 10) (37, 8) (38, 6) (39, 6) (40, 13) (41, 10) (42, 5) (43, 3) (44, 2) (45, 4) (46, 1) (47, 2) (50, 2) (51, 3) (52, 1) (53, 2) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 101.166\n",
      "INFO:tensorflow:loss = 459.334, step = 16501 (0.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.458\n",
      "INFO:tensorflow:loss = 473.97308, step = 16601 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.066\n",
      "INFO:tensorflow:loss = 487.33423, step = 16701 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.851\n",
      "INFO:tensorflow:loss = 452.42444, step = 16801 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.036\n",
      "INFO:tensorflow:loss = 451.08435, step = 16901 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.364\n",
      "INFO:tensorflow:loss = 464.23026, step = 17001 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.349\n",
      "INFO:tensorflow:loss = 451.41385, step = 17101 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.491\n",
      "INFO:tensorflow:loss = 462.97806, step = 17201 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.576\n",
      "INFO:tensorflow:loss = 442.48016, step = 17301 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.844\n",
      "INFO:tensorflow:loss = 452.3904, step = 17401 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.129\n",
      "INFO:tensorflow:loss = 444.27496, step = 17501 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.731\n",
      "INFO:tensorflow:loss = 421.38327, step = 17601 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.48\n",
      "INFO:tensorflow:loss = 461.21222, step = 17701 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.537\n",
      "INFO:tensorflow:loss = 507.87915, step = 17801 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.364\n",
      "INFO:tensorflow:loss = 473.52963, step = 17901 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.924\n",
      "INFO:tensorflow:loss = 472.25116, step = 18001 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.015\n",
      "INFO:tensorflow:loss = 457.7665, step = 18101 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.093\n",
      "INFO:tensorflow:loss = 488.00928, step = 18201 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.511\n",
      "INFO:tensorflow:loss = 466.98676, step = 18301 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.487\n",
      "INFO:tensorflow:loss = 518.01575, step = 18401 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.435\n",
      "INFO:tensorflow:loss = 471.8548, step = 18501 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.837\n",
      "INFO:tensorflow:loss = 480.09073, step = 18601 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.445\n",
      "INFO:tensorflow:loss = 508.59384, step = 18701 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.818\n",
      "INFO:tensorflow:loss = 496.27274, step = 18801 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.322\n",
      "INFO:tensorflow:loss = 480.47684, step = 18901 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.652\n",
      "INFO:tensorflow:loss = 511.19626, step = 19001 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.649\n",
      "INFO:tensorflow:loss = 495.3542, step = 19101 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.162\n",
      "INFO:tensorflow:loss = 466.203, step = 19201 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.44\n",
      "INFO:tensorflow:loss = 464.45822, step = 19301 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.815\n",
      "INFO:tensorflow:loss = 494.31653, step = 19401 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.443\n",
      "INFO:tensorflow:loss = 501.2164, step = 19501 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.573\n",
      "INFO:tensorflow:loss = 499.55258, step = 19601 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.048\n",
      "INFO:tensorflow:loss = 478.5863, step = 19701 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.454\n",
      "INFO:tensorflow:loss = 489.80566, step = 19801 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.572\n",
      "INFO:tensorflow:loss = 462.9422, step = 19901 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.678\n",
      "INFO:tensorflow:loss = 487.0733, step = 20001 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.346\n",
      "INFO:tensorflow:loss = 512.9665, step = 20101 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.487\n",
      "INFO:tensorflow:loss = 450.73984, step = 20201 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.821\n",
      "INFO:tensorflow:loss = 438.3243, step = 20301 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.726\n",
      "INFO:tensorflow:loss = 510.32544, step = 20401 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.639\n",
      "INFO:tensorflow:loss = 472.63977, step = 20501 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.848\n",
      "INFO:tensorflow:loss = 469.31833, step = 20601 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.242\n",
      "INFO:tensorflow:loss = 462.12845, step = 20701 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.812\n",
      "INFO:tensorflow:loss = 500.69983, step = 20801 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.834\n",
      "INFO:tensorflow:loss = 470.9012, step = 20901 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.596\n",
      "INFO:tensorflow:loss = 474.04312, step = 21001 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.833\n",
      "INFO:tensorflow:loss = 534.6106, step = 21101 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.603\n",
      "INFO:tensorflow:loss = 476.89346, step = 21201 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.872\n",
      "INFO:tensorflow:loss = 468.94608, step = 21301 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.645\n",
      "INFO:tensorflow:loss = 533.86774, step = 21401 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.08\n",
      "INFO:tensorflow:loss = 459.73587, step = 21501 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.248\n",
      "INFO:tensorflow:loss = 524.4547, step = 21601 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.927\n",
      "INFO:tensorflow:loss = 492.72552, step = 21701 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.98\n",
      "INFO:tensorflow:loss = 496.25662, step = 21801 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.845\n",
      "INFO:tensorflow:loss = 473.41217, step = 21901 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.611\n",
      "INFO:tensorflow:loss = 481.28406, step = 22001 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.862\n",
      "INFO:tensorflow:loss = 451.1394, step = 22101 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.754\n",
      "INFO:tensorflow:loss = 511.14932, step = 22201 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.964\n",
      "INFO:tensorflow:loss = 509.9819, step = 22301 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.126\n",
      "INFO:tensorflow:loss = 516.53503, step = 22401 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.891\n",
      "INFO:tensorflow:loss = 485.9634, step = 22501 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.208\n",
      "INFO:tensorflow:loss = 513.12683, step = 22601 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.534\n",
      "INFO:tensorflow:loss = 489.96054, step = 22701 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.573\n",
      "INFO:tensorflow:loss = 501.6593, step = 22801 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.472\n",
      "INFO:tensorflow:loss = 488.18234, step = 22901 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.577\n",
      "INFO:tensorflow:loss = 465.52518, step = 23001 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.768\n",
      "INFO:tensorflow:loss = 489.29196, step = 23101 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.972\n",
      "INFO:tensorflow:loss = 467.96774, step = 23201 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.848\n",
      "INFO:tensorflow:loss = 511.53564, step = 23301 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.118\n",
      "INFO:tensorflow:loss = 479.3896, step = 23401 (0.507 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23439 into ./poeem_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 191.78865.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f901f8c3810>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = './poeem_model'\n",
    "poeem_model = tf.estimator.Estimator(model_fn=poeem_model_fn, model_dir=MODEL_DIR, params={})\n",
    "poeem_model.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export item embedding and build index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though theoretically *poeem* does not need to build an index, we can still optionally build one to persist the embedding index into disk. Since *poeem* indexing layer has already done coarse quantization and product quantization internally, the index building just needs to export those values into an index file as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './poeem_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8fd3aa2790>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./poeem_model/model.ckpt-23439\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:22:09.642009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:04:00.0\n",
      "2023-02-08 20:22:09.643895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:05:00.0\n",
      "2023-02-08 20:22:09.645660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:08:00.0\n",
      "2023-02-08 20:22:09.646428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:85:00.0\n",
      "2023-02-08 20:22:09.646656: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.646759: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.646844: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.646925: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.647006: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.647088: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.647170: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:09.647181: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-08 20:22:09.647263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-08 20:22:09.647277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 \n",
      "2023-02-08 20:22:09.647283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y N \n",
      "2023-02-08 20:22:09.647288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y N \n",
      "2023-02-08 20:22:09.647293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N N \n",
      "2023-02-08 20:22:09.647297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N N N \n"
     ]
    }
   ],
   "source": [
    "def predict_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({'query': np.arange(VOCAB_SIZE), 'item': np.arange(VOCAB_SIZE)})\n",
    "    dataset = dataset.batch(VOCAB_SIZE)\n",
    "    return dataset\n",
    "\n",
    "poeem_model = tf.estimator.Estimator(model_fn=poeem_model_fn, model_dir=MODEL_DIR, \n",
    "                                     params={'item_predict': True})\n",
    "results = list(poeem_model.predict(input_fn=predict_input_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the data we need to write into an index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_coarse_code = np.array([e['item_coarse_code'] for e in results])\n",
    "item_code = np.array([e['item_code'] for e in results])\n",
    "item_norm = np.array([e['item_norm'] for e in results])\n",
    "item_id = np.arange(VOCAB_SIZE)\n",
    "coarse_codebook = tf.train.load_variable(MODEL_DIR, 'coarse_centroids')\n",
    "codebook = tf.train.load_variable(MODEL_DIR, 'centroids_k')\n",
    "\n",
    "INDEX_FILE = './poeem.idx'\n",
    "poeem.indexing.write_index_file(INDEX_FILE, codebook, item_id, item_norm, item_code, \n",
    "                                coarse_codebook, item_coarse_code, use_residual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poeem nearest neighbor search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*poeem* ANN search would be in an end-to-end fashion, i.e., input a query and output its nearest neighbor items directly. The most simplest setup would be as follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './poeem_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8fd2235fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "poeem_model = tf.estimator.Estimator(model_fn=poeem_model_fn, model_dir=MODEL_DIR, \n",
    "                                     params={'item_search': True, 'index_file': INDEX_FILE, \n",
    "                                             'topk': 100, 'nprobe': 1, 'metric_type': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure *poeem* rerieval accuracy, we first compute retrieval results for all queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/ops/python/search.py:36: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yuanrz/miniconda3/envs/tf/lib/python3.7/site-packages/poeem/ops/python/search.py:36: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./poeem_model/model.ckpt-23439\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:22:25.571497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:04:00.0\n",
      "2023-02-08 20:22:25.573328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:05:00.0\n",
      "2023-02-08 20:22:25.575088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:08:00.0\n",
      "2023-02-08 20:22:25.576005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:85:00.0\n",
      "2023-02-08 20:22:25.576286: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.576431: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.576560: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.576686: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.576810: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.576953: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.577103: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu\n",
      "2023-02-08 20:22:25.577142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-08 20:22:25.577227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-08 20:22:25.577261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 \n",
      "2023-02-08 20:22:25.577299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y N \n",
      "2023-02-08 20:22:25.577315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y N \n",
      "2023-02-08 20:22:25.577324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N N \n",
      "2023-02-08 20:22:25.577332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N N N \n",
      "2023-02-08 20:22:25.639236: I cpp/search_op.cc:263] use_residual = 1; n_item = 10000; d = 64; n_cluster = 8; K = 256; D = 8\n",
      "2023-02-08 20:22:25.640777: I cpp/search_op.cc:289] cluster 0:1120\n",
      "2023-02-08 20:22:25.640802: I cpp/search_op.cc:289] cluster 1:842\n",
      "2023-02-08 20:22:25.640814: I cpp/search_op.cc:289] cluster 2:1656\n",
      "2023-02-08 20:22:25.640826: I cpp/search_op.cc:289] cluster 3:977\n",
      "2023-02-08 20:22:25.640837: I cpp/search_op.cc:289] cluster 4:1283\n",
      "2023-02-08 20:22:25.640848: I cpp/search_op.cc:289] cluster 5:1135\n",
      "2023-02-08 20:22:25.640860: I cpp/search_op.cc:289] cluster 6:1622\n",
      "2023-02-08 20:22:25.640871: I cpp/search_op.cc:289] cluster 7:1365\n",
      "2023-02-08 20:22:25.714803: I cpp/search_op.cc:305] >>> query, batch_size:10000, num_head:1, d:64\n",
      "2023-02-08 20:22:25.714935: I cpp/search_op.cc:330] step 4\n",
      "2023-02-08 20:22:25.714955: I cpp/search_op.cc:332] use_residual_:1, n_item_:10000, n_neighbor:100, n_probe:1, batch_size:10000, metric_type:0\n",
      "2023-02-08 20:22:25.714967: I cpp/search_op.cc:338] d:64, sub_dim:8, d_:64, D:8, K_:256, n_cluser:8\n",
      "2023-02-08 20:22:25.714978: I cpp/search_op.cc:341] code8.size():80000, code16.size():0, codebook_.size:16384, centroid_vec_.size:512, assignment_.size:10000\n",
      "2023-02-08 20:22:25.714989: I cpp/search_op.cc:346] num_thread for finding the nearest n_probe centroids:0\n",
      "2023-02-08 20:22:25.714999: I cpp/search_op.cc:348] num_thread for searching each vector in n_probe centroids:0\n",
      "2023-02-08 20:22:26.412903: I cpp/search_op.cc:452] Elapsed time: 698.096 ms\n",
      "2023-02-08 20:22:26.412970: I cpp/search_op.cc:453] Elapsed time 1: 20.3035 ms\n",
      "2023-02-08 20:22:26.412978: I cpp/search_op.cc:455] Elapsed time 2: 466.035 ms\n",
      "2023-02-08 20:22:26.412983: I cpp/search_op.cc:457] Elapsed time 3: 190.195 ms\n"
     ]
    }
   ],
   "source": [
    "def search_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({'query': np.arange(VOCAB_SIZE)})\n",
    "    dataset = dataset.batch(VOCAB_SIZE)\n",
    "    return dataset\n",
    "\n",
    "results = list(poeem_model.predict(input_fn=search_input_fn))\n",
    "neighbors = np.array([e['neighbors'] for e in results])\n",
    "scores = np.array([e['scores'] for e in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follows the search function interface as above Brute Force and Faiss search, so we can reuse the precision_at_k utitity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poeem_search(query_id, items, k=100):\n",
    "    return neighbors[query_id, :k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall precision@100 =  0.9814590000000002\n"
     ]
    }
   ],
   "source": [
    "precision_at_100 = [precision_at_k(poeem_search, i, None, k=100) for i in range(VOCAB_SIZE)]\n",
    "print(\"overall precision@100 = \", np.mean(precision_at_100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Note that Poeem could reach higher retrieval accuracy than Faiss, by jointly learning the embedding index and retrieval model.\n",
    "\n",
    "This is a simple example as a quick rampup for beginners. For more rigorous experimental results to draw conclusions, please checkout our SIGIR paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "992033dd536c22e618ac7d802c4e6d2757f80f0fca1e8ce1b58f96c0ab557f5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
